{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "\n",
    "samples = open(os.path.join(ROOT, \"dataset\", \"metadata.txt\")).read().splitlines()\n",
    "randomized = random.sample(samples, len(samples))\n",
    "\n",
    "train_count = int(len(randomized) * 0.85)\n",
    "\n",
    "train_dataset = randomized[:train_count]\n",
    "val_dataset = randomized[train_count:]\n",
    "\n",
    "train_metadata_outpath = os.path.join(ROOT, \"dataset\", \"train.txt\")\n",
    "val_metadata_outpath = os.path.join(ROOT, \"dataset\", \"val.txt\")\n",
    "\n",
    "f_train = open(train_metadata_outpath, \"w\")\n",
    "f_train.write(\"\\n\".join(train_dataset))\n",
    "f_train.close()\n",
    "\n",
    "f_val = open(val_metadata_outpath, \"w\")\n",
    "f_val.write(\"\\n\".join(val_dataset))\n",
    "f_val.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://huggingface.co/Gatozu35/tortoise-tts/resolve/main/dvae.pth -O experiments/dvae.pth\n",
    "!wget https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/autoregressive.pth -O experiments/autoregressive.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===CALCULATED SETTINGS===\n",
      "train_bs=64 val_bs=32\n",
      "val_freq=300 lr_decay_steps=[224720, 449440, 629216, 808992]\n",
      "print_freq=100 save_checkpoint_freq=300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "\n",
    "DEFAULT_TRAIN_BS = 64\n",
    "DEFAULT_VAL_BS = 32\n",
    "Dataset_Training_Path = os.path.join(ROOT, \"dataset/train.txt\")\n",
    "ValidationDataset_Training_Path = os.path.join(ROOT, \"dataset/val.txt\")\n",
    "\n",
    "if Dataset_Training_Path == ValidationDataset_Training_Path:\n",
    "    print(\"WARNING: training dataset path == validation dataset path!!!\")\n",
    "    print(\n",
    "        \"\\tThis is technically okay but will make all of the validation metrics useless. \"\n",
    "    )\n",
    "    print(\n",
    "        \"it will also SUBSTANTIALLY slow down the rate of training, because validation datasets are supposed to be much smaller than training ones.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def txt_file_lines(p: str) -> int:\n",
    "    return len(Path(p).read_text().strip().split(\"\\n\"))\n",
    "\n",
    "\n",
    "training_samples = txt_file_lines(Dataset_Training_Path)\n",
    "val_samples = txt_file_lines(ValidationDataset_Training_Path)\n",
    "\n",
    "if training_samples < 128:\n",
    "    print(\n",
    "        \"WARNING: very small dataset! the smallest dataset tested thus far had ~200 samples.\"\n",
    "    )\n",
    "if val_samples < 20:\n",
    "    print(\n",
    "        \"WARNING: very small validation dataset! val batch size will be scaled down to account\"\n",
    "    )\n",
    "\n",
    "\n",
    "def div_spillover(n: int, bs: int) -> int:  # returns new batch size\n",
    "    epoch_steps, remain = divmod(n, bs)\n",
    "    if epoch_steps * 2 > bs:\n",
    "        return bs  # don't bother optimising this stuff if epoch_steps are high\n",
    "    if not remain:\n",
    "        return bs  # unlikely but still\n",
    "\n",
    "    if remain * 2 < bs:  # \"easier\" to get rid of remainder -- should increase bs\n",
    "        target_bs = n // epoch_steps\n",
    "    else:  # easier to increase epoch_steps by 1 -- decrease bs\n",
    "        target_bs = n // (epoch_steps + 1)\n",
    "    assert n % target_bs < epoch_steps + 2  # should be very few extra\n",
    "    return target_bs\n",
    "\n",
    "\n",
    "if training_samples < DEFAULT_TRAIN_BS:\n",
    "    print(\n",
    "        \"WARNING: dataset is smaller than a single batch. This will almost certainly perform poorly. Trying anyway\"\n",
    "    )\n",
    "    train_bs = training_samples\n",
    "else:\n",
    "    train_bs = div_spillover(training_samples, DEFAULT_TRAIN_BS)\n",
    "if val_samples < DEFAULT_VAL_BS:\n",
    "    val_bs = val_samples\n",
    "else:\n",
    "    val_bs = div_spillover(val_samples, DEFAULT_VAL_BS)\n",
    "\n",
    "steps_per_epoch = training_samples // train_bs\n",
    "lr_decay_epochs = [20, 40, 56, 72]\n",
    "lr_decay_steps = [steps_per_epoch * e for e in lr_decay_epochs]\n",
    "print_freq = min(100, max(20, steps_per_epoch))\n",
    "val_freq = save_checkpoint_freq = print_freq * 3\n",
    "\n",
    "print(\"===CALCULATED SETTINGS===\")\n",
    "print(f\"{train_bs=} {val_bs=}\")\n",
    "print(f\"{val_freq=} {lr_decay_steps=}\")\n",
    "print(f\"{print_freq=} {save_checkpoint_freq=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment_Name = \"Test1\"  # @param {type:\"string\"}\n",
    "Dataset_Training_Name = \"TestDataset\"  # @param {type:\"string\"}\n",
    "ValidationDataset_Name = (\n",
    "    \"TestValidation\"  # this seems to be useless??? @param {type:\"string\"}\n",
    ")\n",
    "SaveTrainingStates = False  # @param {type:\"boolean\"}\n",
    "Keep_Last_N_Checkpoints = 0  # @param {type:\"slider\", min:0, max:10, step:1}\n",
    "\n",
    "Fp16 = False  # @param {type:\"boolean\"}\n",
    "Use8bit = True  # @param {type:\"boolean\"}\n",
    "TrainingRate = \"1e-5\"  # @param {type:\"string\"}\n",
    "TortoiseCompat = True  # @param {type:\"boolean\"}\n",
    "\n",
    "TrainBS = \"\"  # @param {type:\"string\"}\n",
    "ValBS = \"\"  # @param {type:\"string\"}\n",
    "ValFreq = \"\"  # @param {type:\"string\"}\n",
    "LRDecaySteps = \"\"  # @param {type:\"string\"}\n",
    "PrintFreq = \"\"  # @param {type:\"string\"}\n",
    "SaveCheckpointFreq = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "\n",
    "def take(orig, override):\n",
    "    if override == \"\":\n",
    "        return orig\n",
    "    return type(orig)(override)\n",
    "\n",
    "\n",
    "train_bs = take(train_bs, TrainBS)\n",
    "val_bs = take(val_bs, ValBS)\n",
    "val_freq = take(val_freq, ValFreq)\n",
    "lr_decay_steps = eval(LRDecaySteps) if LRDecaySteps else lr_decay_steps\n",
    "print_freq = take(print_freq, PrintFreq)\n",
    "save_checkpoint_freq = take(save_checkpoint_freq, SaveCheckpointFreq)\n",
    "assert len(lr_decay_steps) == 4\n",
    "gen_lr_steps = \", \".join(str(v) for v in lr_decay_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('experiments/EXAMPLE_gpt.yml', <http.client.HTTPMessage at 0x762e2af434a0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/152334H/DL-Art-School/master/experiments/EXAMPLE_gpt.yml\",\n",
    "    \"experiments/EXAMPLE_gpt.yml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "!sed -i 's/batch_size: 128/batch_size: '\"$train_bs\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
    "!sed -i 's/batch_size: 64/batch_size: '\"$val_bs\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
    "!sed -i 's/val_freq: 500/val_freq: '\"$val_freq\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
    "!sed -i 's/500, 1000, 1400, 1800/'\"$gen_lr_steps\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
    "!sed -i 's/print_freq: 100/print_freq: '\"$print_freq\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
    "!sed -i 's/save_checkpoint_freq: 500/save_checkpoint_freq: '\"$save_checkpoint_freq\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
    "\n",
    "!sed -i 's+CHANGEME_validation_dataset_name+'\"$ValidationDataset_Name\"'+g' ./experiments/EXAMPLE_gpt.yml\n",
    "!sed -i 's+CHANGEME_path_to_validation_dataset+'\"$ValidationDataset_Training_Path\"'+g' ./experiments/EXAMPLE_gpt.yml\n",
    "if(Fp16==True):\n",
    "  os.system(\"sed -i 's+fp16: false+fp16: true+g' ./experiments/EXAMPLE_gpt.yml\")\n",
    "!sed -i 's/use_8bit: true/use_8bit: '\"$Use8bit\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
    "\n",
    "!sed -i 's/disable_state_saving: true/disable_state_saving: '\"$SaveTrainingStates\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
    "!sed -i 's/tortoise_compat: True/tortoise_compat: '\"$TortoiseCompat\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
    "!sed -i 's/number_of_checkpoints_to_save: 0/number_of_checkpoints_to_save: '\"$Keep_Last_N_Checkpoints\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
    "\n",
    "\n",
    "!sed -i 's/CHANGEME_training_dataset_name/'\"$Dataset_Training_Name\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
    "!sed -i 's/CHANGEME_your_experiment_name/'\"$Experiment_Name\"'/g' ./experiments/EXAMPLE_gpt.yml\n",
    "!sed -i 's+CHANGEME_path_to_training_dataset+'\"$Dataset_Training_Path\"'+g' ./experiments/EXAMPLE_gpt.yml\n",
    "\n",
    "\n",
    "if (not TrainingRate==\"1e-5\"):\n",
    "  os.system(\"sed -i 's+!!float 1e-5 # CHANGEME:+!!float '\" + TrainingRate + \"' #+g' ./experiments/EXAMPLE_gpt.yml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/DL-Art-School/codes\n",
    "\n",
    "!python3 train.py -opt ../experiments/EXAMPLE_gpt.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tortoise-tts-fast fork\n",
    "# use the new --ar-checkpoint option with\n",
    "# /path/to/DL-Art-School/experiments/<INSERT EXPERIMENT NAME HERE>/models/<MOST RECENT STEPS>_gpt.pth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
